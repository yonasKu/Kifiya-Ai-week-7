{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path = '../telegram_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values in the 'Message' column:\n",
      "Number of NaN values in 'Message' column: 139\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for NaN values in the 'Message' column:\")\n",
    "nan_count = df['Message'].isnull().sum()\n",
    "print(f\"Number of NaN values in 'Message' column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after dropping NaN values in 'Message' column: (157, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = df.dropna(subset=['Message'])\n",
    "\n",
    "# Print the shape of the dataset after dropping NaN values in the \"Message\" column\n",
    "print(f\"Dataset shape after dropping NaN values in 'Message' column: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>https://t.me/ZemenExpress</td>\n",
       "      <td>5352</td>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...</td>\n",
       "      <td>2024-09-30T09:20:55+00:00</td>\n",
       "      <td>photos\\httpstmeZemenExpress_5352jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>https://t.me/ZemenExpress</td>\n",
       "      <td>5351</td>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...</td>\n",
       "      <td>2024-09-30T09:20:47+00:00</td>\n",
       "      <td>photos\\httpstmeZemenExpress_5351jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>https://t.me/ZemenExpress</td>\n",
       "      <td>5346</td>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...</td>\n",
       "      <td>2024-09-30T09:20:43+00:00</td>\n",
       "      <td>photos\\httpstmeZemenExpress_5346jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>https://t.me/ZemenExpress</td>\n",
       "      <td>5341</td>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ K...</td>\n",
       "      <td>2024-09-29T08:17:03+00:00</td>\n",
       "      <td>photos\\httpstmeZemenExpress_5341jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>https://t.me/ZemenExpress</td>\n",
       "      <td>5340</td>\n",
       "      <td>ğŸ’¥ğŸ’¥...............ğŸŒ.................ğŸ’¥ğŸ’¥\\n\\nâ“ á‰ áˆ¨á...</td>\n",
       "      <td>2024-09-28T16:44:37+00:00</td>\n",
       "      <td>photos\\httpstmeZemenExpress_5340jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel Title           Channel Username    ID  \\\n",
       "0   Zemen ExpressÂ®  https://t.me/ZemenExpress  5352   \n",
       "1   Zemen ExpressÂ®  https://t.me/ZemenExpress  5351   \n",
       "6   Zemen ExpressÂ®  https://t.me/ZemenExpress  5346   \n",
       "11  Zemen ExpressÂ®  https://t.me/ZemenExpress  5341   \n",
       "12  Zemen ExpressÂ®  https://t.me/ZemenExpress  5340   \n",
       "\n",
       "                                              Message  \\\n",
       "0   ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...   \n",
       "1   ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...   \n",
       "6   ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...   \n",
       "11  ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ K...   \n",
       "12  ğŸ’¥ğŸ’¥...............ğŸŒ.................ğŸ’¥ğŸ’¥\\n\\nâ“ á‰ áˆ¨á...   \n",
       "\n",
       "                         Date                           Media Path  \n",
       "0   2024-09-30T09:20:55+00:00  photos\\httpstmeZemenExpress_5352jpg  \n",
       "1   2024-09-30T09:20:47+00:00  photos\\httpstmeZemenExpress_5351jpg  \n",
       "6   2024-09-30T09:20:43+00:00  photos\\httpstmeZemenExpress_5346jpg  \n",
       "11  2024-09-29T08:17:03+00:00  photos\\httpstmeZemenExpress_5341jpg  \n",
       "12  2024-09-28T16:44:37+00:00  photos\\httpstmeZemenExpress_5340jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...\n",
       "1      ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...\n",
       "6      ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒMu...\n",
       "11     ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ K...\n",
       "12     ğŸ’¥ğŸ’¥...............ğŸŒ.................ğŸ’¥ğŸ’¥\\n\\nâ“ á‰ áˆ¨á...\n",
       "                             ...                        \n",
       "284    ğŸ’¥ğŸ’¥....................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ ...\n",
       "289    ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ¯Ki...\n",
       "290    ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒSp...\n",
       "291    ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒSp...\n",
       "295    ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ A...\n",
       "Name: Message, Length: 157, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_df=df['Message']\n",
    "message_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Channel Title           Channel Username    ID  \\\n",
      "0   Zemen ExpressÂ®  https://t.me/ZemenExpress  5352   \n",
      "1   Zemen ExpressÂ®  https://t.me/ZemenExpress  5351   \n",
      "6   Zemen ExpressÂ®  https://t.me/ZemenExpress  5346   \n",
      "11  Zemen ExpressÂ®  https://t.me/ZemenExpress  5341   \n",
      "12  Zemen ExpressÂ®  https://t.me/ZemenExpress  5340   \n",
      "\n",
      "                                              Message  \\\n",
      "0   ...................................\\n\\nMulti-p...   \n",
      "1   ...................................\\n\\nMulti-p...   \n",
      "6   ...................................\\n\\nMulti-p...   \n",
      "11  ...................................\\n\\n Kemei ...   \n",
      "12  ................................\\n\\n á‰ áˆ¨áá‰µ á‰€áŠ•á‹ ...   \n",
      "\n",
      "                         Date                           Media Path  \n",
      "0   2024-09-30T09:20:55+00:00  photos\\httpstmeZemenExpress_5352jpg  \n",
      "1   2024-09-30T09:20:47+00:00  photos\\httpstmeZemenExpress_5351jpg  \n",
      "6   2024-09-30T09:20:43+00:00  photos\\httpstmeZemenExpress_5346jpg  \n",
      "11  2024-09-29T08:17:03+00:00  photos\\httpstmeZemenExpress_5341jpg  \n",
      "12  2024-09-28T16:44:37+00:00  photos\\httpstmeZemenExpress_5340jpg  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply the function to the 'Message' column\n",
    "df['Message'] = df['Message'].apply(remove_emojis)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Channel Title           Channel Username    ID  \\\n",
      "0   Zemen ExpressÂ®  https://t.me/ZemenExpress  5352   \n",
      "1   Zemen ExpressÂ®  https://t.me/ZemenExpress  5351   \n",
      "6   Zemen ExpressÂ®  https://t.me/ZemenExpress  5346   \n",
      "11  Zemen ExpressÂ®  https://t.me/ZemenExpress  5341   \n",
      "12  Zemen ExpressÂ®  https://t.me/ZemenExpress  5340   \n",
      "\n",
      "                                              Message  \\\n",
      "0   á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ á‹¨áˆ˜áˆµá‰³á‹ˆá‰µ áŒá‹µáŒ“á‹³ áˆ³áˆ…áŠ–á‰½ áŠ¨ á‰¥áˆ­áŒ­á‰† á‹¨á‰°áˆ°áˆ« áˆˆá‰¤á‰°á‹ á‰°áŒ¨áˆ›áˆª...   \n",
      "1   á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ á‹¨áˆ˜áˆµá‰³á‹ˆá‰µ áŒá‹µáŒ“á‹³ áˆ³áˆ…áŠ–á‰½ áŠ¨ á‰¥áˆ­áŒ­á‰† á‹¨á‰°áˆ°áˆ« áˆˆá‰¤á‰°á‹ á‰°áŒ¨áˆ›áˆª...   \n",
      "6   á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ á‹¨áˆ˜áˆµá‰³á‹ˆá‰µ áŒá‹µáŒ“á‹³ áˆ³áˆ…áŠ–á‰½ áŠ¨ á‰¥áˆ­áŒ­á‰† á‹¨á‰°áˆ°áˆ« áˆˆá‰¤á‰°á‹ á‰°áŒ¨áˆ›áˆª...   \n",
      "11  áŠ¨ 80 áŠ¥áˆµáŠ¨ 220 áˆ™á‰€á‰µ á‹«áˆˆá‹ 360 á‹¨áˆšáˆ½áŠ¨áˆ¨áŠ¨áˆ­ áˆˆáˆáˆ‰áˆ á‹¨á€áŒ‰áˆ­ áŠ á‹­áŠ...   \n",
      "12  á‰ áˆ¨áá‰µ á‰€áŠ•á‹ áˆ±á‰… áˆ‹á‹­ áˆ˜áˆµá‰°áŠ“áŒˆá‹µ áˆˆáˆá‰µáˆáˆáŒ‰ á‹á‹µ á‹°áŠ•á‰ áŠá‰»á‰½áŠ• áŠáŒˆ áŠ¨áŒ á‹‹...   \n",
      "\n",
      "                         Date                           Media Path  \n",
      "0   2024-09-30T09:20:55+00:00  photos\\httpstmeZemenExpress_5352jpg  \n",
      "1   2024-09-30T09:20:47+00:00  photos\\httpstmeZemenExpress_5351jpg  \n",
      "6   2024-09-30T09:20:43+00:00  photos\\httpstmeZemenExpress_5346jpg  \n",
      "11  2024-09-29T08:17:03+00:00  photos\\httpstmeZemenExpress_5341jpg  \n",
      "12  2024-09-28T16:44:37+00:00  photos\\httpstmeZemenExpress_5340jpg  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_message(message):\n",
    "    # Use regex to retain only Amharic characters, numbers, and spaces\n",
    "    message = re.sub(r'[^\\u1200-\\u137F0-9\\s]', '', message)  # Retain Amharic characters and numbers\n",
    "    message = re.sub(r'\\s+', ' ', message)  # Replace multiple spaces with one\n",
    "    \n",
    "    return message.strip()\n",
    "\n",
    "# Apply the preprocessing function to the 'Message' column\n",
    "df['Message'] = df['Message'].apply(preprocess_message)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if applicable)\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if applicable)\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# def label_message_utf8_with_birr(message):\n",
    "#     # Tokenize the message\n",
    "#     tokens = re.findall(r'\\S+', message)\n",
    "    \n",
    "#     final_labeled_tokens = []\n",
    "#     found_price_or_loc = False  # Flag to indicate when we find the first price or location\n",
    "\n",
    "#     # Predefined location keywords\n",
    "#     loc_keywords = {\n",
    "#         'á‰2á’á‹«áˆ³', 'á‰1áˆ˜áŒˆáŠ“áŠ›', 'áŒŠá‹®áˆ­áŒŠáˆµ áŠ á‹°á‰£á‰£á‹­', 'á’á‹«áˆ³', \n",
    "#         'á‰…áˆ­áŠ•áŒ«á', 'áˆ˜áˆ°áˆ¨á‰µ á‹°á‹áˆ­ áˆáˆ', 'áŒŠá‹®áˆ­áŒŠáˆµ', \n",
    "#         'áŠ á‹°á‰£á‰£á‹­', 'áˆ«áˆ˜á‰µá‰³á‰¦áˆ­áŠ¦á‹³áˆ…áŠ•áƒ', 'áˆ˜áˆ°áˆ¨á‰µ', 'á‹°á‹áˆ­', 'áˆáˆ'\n",
    "#     }\n",
    "\n",
    "#     # Iterate through tokens\n",
    "#     for i, token in enumerate(tokens):\n",
    "#         # Default label is O\n",
    "#         final_label = 'O'\n",
    "\n",
    "#         # If price or location has already been found\n",
    "#         if found_price_or_loc:\n",
    "#             # Keep checking for new price or location\n",
    "#             if re.match(r'^[\\d,]+(\\.\\d{1,2})?$', token):  # Numeric check with commas and decimals\n",
    "#                 price_before = (i > 0 and tokens[i - 1] in {'ETB', 'á‹‹áŒ‹', '$', 'á‰¥áˆ­'})\n",
    "#                 price_after = (i < len(tokens) - 1 and tokens[i + 1] in {'ETB', 'á‹‹áŒ‹', '$', 'á‰¥áˆ­'})\n",
    "#                 if price_before or price_after:\n",
    "#                     final_label = 'I-PRICE'\n",
    "#             elif token in loc_keywords or any(loc in token for loc in loc_keywords):\n",
    "#                 final_label = 'I-LOC'\n",
    "\n",
    "#             # After first location/price, everything not `I-PRICE` or `I-LOC` is `O`\n",
    "#             final_labeled_tokens.append(f\"{token} {final_label}\")\n",
    "#             continue\n",
    "\n",
    "#         # Check if the token is a price (before a price or location is found)\n",
    "#         if re.match(r'^[\\d,]+(\\.\\d{1,2})?$', token):  # Numeric check with commas and decimals\n",
    "#             price_before = (i > 0 and tokens[i - 1] in {'ETB', 'á‹‹áŒ‹','á‹‹áŒ‹á¦', '$', 'á‰¥áˆ­'})\n",
    "#             price_after = (i < len(tokens) - 1 and tokens[i + 1] in {'ETB', 'á‹‹áŒ‹', '$', 'á‰¥áˆ­'})\n",
    "#             if price_before or price_after:\n",
    "#                 final_label = 'I-PRICE'\n",
    "#                 found_price_or_loc = True  # Set flag after finding the first price\n",
    "\n",
    "#         # Check if the token is a location (before a price or location is found)\n",
    "#         elif token in loc_keywords or any(loc in token for loc in loc_keywords):\n",
    "#             final_label = 'I-LOC'\n",
    "#             found_price_or_loc = True  # Set flag after finding the first location\n",
    "\n",
    "#         # If the token is neither a price nor a location, label it as a product initially\n",
    "#         if final_label == 'O':\n",
    "#             if i == 0:\n",
    "#                 final_label = 'B-PRODUCT'\n",
    "#             else:\n",
    "#                 final_label = 'I-PRODUCT'\n",
    "\n",
    "#         # Append the labeled token to the final list\n",
    "#         final_labeled_tokens.append(f\"{token} {final_label}\")\n",
    "\n",
    "#     return \"\\n\".join(final_labeled_tokens)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Apply the updated function to the messages in the DataFrame\n",
    "# df['Labeled_Message'] = df['Message'].apply(label_message_utf8_with_birr)\n",
    "\n",
    "# # Display the updated DataFrame with labeled messages\n",
    "# print(df[['Message', 'Labeled_Message']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  \\\n",
      "0  á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ á‹¨áˆ˜áˆµá‰³á‹ˆá‰µ áŒá‹µáŒ“á‹³ áˆ³áˆ…áŠ–á‰½ áŠ¨ á‰¥áˆ­áŒ­á‰† á‹¨á‰°áˆ°áˆ« áˆˆá‰¤á‰°á‹ á‰°áŒ¨áˆ›áˆª...   \n",
      "1  á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ á‹¨áˆ˜áˆµá‰³á‹ˆá‰µ áŒá‹µáŒ“á‹³ áˆ³áˆ…áŠ–á‰½ áŠ¨ á‰¥áˆ­áŒ­á‰† á‹¨á‰°áˆ°áˆ« áˆˆá‰¤á‰°á‹ á‰°áŒ¨áˆ›áˆª...   \n",
      "2  á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ á‹¨áˆ˜áˆµá‰³á‹ˆá‰µ áŒá‹µáŒ“á‹³ áˆ³áˆ…áŠ–á‰½ áŠ¨ á‰¥áˆ­áŒ­á‰† á‹¨á‰°áˆ°áˆ« áˆˆá‰¤á‰°á‹ á‰°áŒ¨áˆ›áˆª...   \n",
      "3  áŠ¨ 80 áŠ¥áˆµáŠ¨ 220 áˆ™á‰€á‰µ á‹«áˆˆá‹ 360 á‹¨áˆšáˆ½áŠ¨áˆ¨áŠ¨áˆ­ áˆˆáˆáˆ‰áˆ á‹¨á€áŒ‰áˆ­ áŠ á‹­áŠ...   \n",
      "4  á‰ áˆ¨áá‰µ á‰€áŠ•á‹ áˆ±á‰… áˆ‹á‹­ áˆ˜áˆµá‰°áŠ“áŒˆá‹µ áˆˆáˆá‰µáˆáˆáŒ‰ á‹á‹µ á‹°áŠ•á‰ áŠá‰»á‰½áŠ• áŠáŒˆ áŠ¨áŒ á‹‹...   \n",
      "\n",
      "                                     Labeled_Message  \n",
      "0  á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ O\\ná‹¨áˆ˜áˆµá‰³á‹ˆá‰µ O\\náŒá‹µáŒ“á‹³ O\\náˆ³áˆ…áŠ–á‰½ O\\náŠ¨ O\\ná‰¥áˆ­áŒ­á‰†...  \n",
      "1  á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ O\\ná‹¨áˆ˜áˆµá‰³á‹ˆá‰µ O\\náŒá‹µáŒ“á‹³ O\\náˆ³áˆ…áŠ–á‰½ O\\náŠ¨ O\\ná‰¥áˆ­áŒ­á‰†...  \n",
      "2  á‰£áˆˆá‰¥á‹™áŒ¥á‰…áˆ O\\ná‹¨áˆ˜áˆµá‰³á‹ˆá‰µ O\\náŒá‹µáŒ“á‹³ O\\náˆ³áˆ…áŠ–á‰½ O\\náŠ¨ O\\ná‰¥áˆ­áŒ­á‰†...  \n",
      "3  áŠ¨ O\\n80 O\\náŠ¥áˆµáŠ¨ O\\n220 O\\náˆ™á‰€á‰µ O\\ná‹«áˆˆá‹ O\\n360 O\\n...  \n",
      "4  á‰ áˆ¨áá‰µ O\\ná‰€áŠ•á‹ O\\náˆ±á‰… O\\náˆ‹á‹­ O\\náˆ˜áˆµá‰°áŠ“áŒˆá‹µ O\\náˆˆáˆá‰µáˆáˆáŒ‰ O\\...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def label_message_utf8_with_birr(message):\n",
    "    # Tokenize the message\n",
    "    tokens = re.findall(r'\\S+', message)\n",
    "    \n",
    "    # Prepare to store the final labels\n",
    "    final_labels = ['O'] * len(tokens)\n",
    "    \n",
    "    # Predefined location keywords\n",
    "    loc_keywords = {\n",
    "        'á‰2á’á‹«áˆ³', 'á‰1áˆ˜áŒˆáŠ“áŠ›', 'áŒŠá‹®áˆ­áŒŠáˆµ áŠ á‹°á‰£á‰£á‹­', 'á’á‹«áˆ³', \n",
    "        'á‰…áˆ­áŠ•áŒ«á', 'áˆ˜áˆ°áˆ¨á‰µ á‹°á‹áˆ­ áˆáˆ', 'áŒŠá‹®áˆ­áŒŠáˆµ', \n",
    "        'áŠ á‹°á‰£á‰£á‹­', 'áˆ«áˆ˜á‰µá‰³á‰¦áˆ­áŠ¦á‹³áˆ…áŠ•áƒ', 'áˆ˜áˆ°áˆ¨á‰µ', 'á‹°á‹áˆ­', 'áˆáˆ',\n",
    "        'áŒ€áˆ', 'áˆ˜áˆ³áˆˆáˆšá‹«', 'áŠ«áˆ«', 'á‹ˆá‹­áˆ« áˆ°áˆáˆ­', 'á‹®áˆƒáŠ•áˆµ', \n",
    "        'áŒ¨áˆ­á‰†áˆµ', 'áŠ á‹²áˆµ áŠ¨á‰°áˆ›', 'áŠ ááŠ•áŒ® á‰ áˆ­', 'áŠ¥áŠ•áŒ¦áŒ¦', \n",
    "        'áˆ˜áŠ«áŠ’áˆ³', 'áŠ á‹«á‰µ', 'áˆœáŠ­áˆ²áŠ®', 'áˆáˆ¨áŠ•áˆ³á‹­', 'áˆ¸áŒáˆŒ', \n",
    "        'á‰¦áˆŒ', 'áŠ á‹«á‰µ', 'áŠ áˆˆáˆ á‰£áŠ•áŠ­', 'áŒá‰°áˆ«', 'á‰ áˆ‹á‹­', \n",
    "        'á‰¦áˆŒ áˆšáŠ«áŠ¤áˆ', 'áˆá‹°á‰³', 'áˆ†áˆˆá‰³', 'áŠ¨áˆšáˆ´', 'áˆˆáŒˆáˆáˆ­', \n",
    "        'áŠ®áˆáŒ', 'áŒ‰áˆˆáˆŒ', 'á‰€áŒ¨áŠ”', 'áŠ áˆ®áŒŒ á‰°áˆ«', 'áˆáˆµ á‹•á‹³', \n",
    "        '4 áŠªáˆ', 'áŠ áˆ«á‰µ áŠªáˆ', 'áˆ³áˆªáˆµ', 'áˆªá‰¼á‹­', 'áŠ á‹á‰¶á‰¢áˆµ á‰°áˆ«', \n",
    "        'á‰„áˆ«', 'á‹¨áŠ«', 'áˆ‹áˆ á‰ áˆ¨á‰µ', 'áŠ á‹¨áˆ­ áŒ¤áŠ“', 'áˆ½áˆ® áˆœá‹³', \n",
    "        'á‰€á‰ áŠ“', 'áˆ˜áŒˆáŠ“áŠ›', '22', 'áˆ€á‹« áˆáˆˆá‰µ', 'á‰ƒáˆŠá‰²', \n",
    "        '4 áŠªáˆ áˆ°á‰£á‰°áŠ›', 'á“áˆµá‰°áˆ­', 'áŠ áˆµáŠ®', 'á‹ˆáˆ áˆ°áˆáˆ­', \n",
    "        'á‰€áˆ«áŠ•á‹®', 'á‹ˆá‹­áˆ« áˆ°áˆáˆ­', 'áŠ«áˆ« á‰†áˆ¬', 'á‹ŠáŠ•áŒá‰µ', \n",
    "        'á‰¦áˆŒ áˆ˜á‹³áˆ…áŠ”á‹“áˆˆáˆ', 'áˆ‹áá‰¶', 'áˆ˜áŠ«áŠ’áˆ³', 'áˆá‹°á‰³', \n",
    "        'áŠ á‰¦áˆ¬', '6 áŠªáˆ', 'áˆµá‹µáˆµá‰µ áŠªáˆ', 'áŠ¦áˆáˆá’á‹«', \n",
    "        'áˆ˜áˆµá‰€áˆ ááˆ‹á‹ˆáˆ­', 'áŒáŒƒáˆ á‰ áˆ¨áŠ•á‹³', 'áŠ áˆá‰£áˆ³á‹°áˆ­', \n",
    "        'á‹®áˆ´á', 'áˆ¸áˆˆá‰³', 'áŒ‰áˆ­á‹µ áˆ¾áˆ‹', 'áŒˆá‹³áˆ áˆ°áˆáˆ­', \n",
    "        'áˆˆáŒˆáˆáˆ­', 'áˆ‹áŠ•á‰»', 'áŠ¡áˆ«áŠ¤áˆ', 'áŒ¦áˆ­ áˆá‹­áˆá‰½', \n",
    "        'á‰ áˆ¸áˆŒá‹­', 'áˆµá‰³á‹²á‹¨áˆ', 'áˆ³áˆ­ á‰¤á‰µ', 'áŒ‹á‹œá‰¦', \n",
    "        'á‹­áˆ½á‹­ á‹°á‰ áˆŒ', 'á‰ á‰…áˆ á‰¤á‰µ', 'ááˆ á‹ˆáˆƒ', 'áˆ˜áŠáŠ•', \n",
    "        'á‰€áŒ¨áŠ” áˆ¸áˆˆá‰³', 'á‰ºá‰ºáŠ’á‹«', 'áŠ á‰µáˆ‹áˆµ', 'á‰¥áˆµáˆ«á‰° áŒˆá‰¥áˆ­áŠ¤áˆ', \n",
    "        'áˆ˜áˆ¿áˆˆáŠªá‹«', 'áŠ®áˆáŒ', 'áŠ áˆ«á‹³', 'áŠ•á‹áˆµ áˆµáˆáŠ­', \n",
    "        'á‰‚áˆ­á‰†áˆµ', 'á’á‹«áˆ³', 'áˆ°áˆœáŠ• áˆ›á‹˜áŒ‹áŒƒ', 'áŒˆáˆ­áŒ‚ áˆ°á‰£á‰°áŠ›', \n",
    "        'áˆ˜áˆ­áŠ«á‰¶', 'áŠ á‹²áˆ± áŒˆá‰ á‹«', 'áŠ á‰ƒá‰‚ á‰ƒáˆŠá‰²', \n",
    "        'áŠ®áˆáŒ á‰€áˆ«áŠ•á‹­á‹®', 'áŠ¢áˆá”áˆªá‹«áˆ', '4áŠªáˆ'\n",
    "    }\n",
    "    \n",
    "    # Iterate through tokens\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Check for price\n",
    "        if re.match(r'^[\\d,]+(\\.\\d{1,2})?$', token):  # Numeric check with commas and decimals\n",
    "            price_before = (i > 0 and tokens[i - 1] in {'ETB', 'á‹‹áŒ‹', '$', 'á‰¥áˆ­'})\n",
    "            price_after = (i < len(tokens) - 1 and tokens[i + 1] in {'ETB', 'á‹‹áŒ‹', '$', 'á‰¥áˆ­'})\n",
    "            if price_before or price_after:\n",
    "                final_labels[i] = 'I-PRICE'\n",
    "                \n",
    "                # Label previous tokens as I-PRODUCT\n",
    "                for j in range(i - 1, -1, -1):  # Backtrack from the price\n",
    "                    if final_labels[j] == 'O':\n",
    "                        final_labels[j] = 'I-PRODUCT'\n",
    "                    else:\n",
    "                        break  # Stop if we hit a non-O label\n",
    "        \n",
    "        # Check if the token is the term á‹‹áŒ‹\n",
    "        elif token == 'á‹‹áŒ‹á¦':\n",
    "            final_labels[i] = 'B-PRICE'\n",
    "            # Label previous tokens as I-PRODUCT\n",
    "            for j in range(i - 1, -1, -1):  # Backtrack from á‹‹áŒ‹\n",
    "                if final_labels[j] == 'O':\n",
    "                    final_labels[j] = 'I-PRODUCT'\n",
    "                else:\n",
    "                    break  # Stop if we hit a non-O label\n",
    "\n",
    "        # Check if the token is a location\n",
    "        elif token in loc_keywords or any(loc in token for loc in loc_keywords):\n",
    "            final_labels[i] = 'I-LOC'\n",
    "\n",
    "    # Combine tokens with their final labels\n",
    "    labeled_tokens = [f\"{token} {label}\" for token, label in zip(tokens, final_labels)]\n",
    "    \n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "\n",
    "\n",
    "# Apply the updated function to the messages in the DataFrame\n",
    "df['Labeled_Message'] = df['Message'].apply(label_message_utf8_with_birr)\n",
    "\n",
    "# Display the updated DataFrame with labeled messages\n",
    "print(df[['Message', 'Labeled_Message']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated labeled dataset to a file in CoNLL format\n",
    "labeled_data_birr_path = 'labeled_telegram_product_price_location.txt-'\n",
    "with open(labeled_data_birr_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
